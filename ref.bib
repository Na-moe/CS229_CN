@inproceedings{he2016resnet,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={770-778},
  year={2016}
}

@inproceedings{opper1995statistical,
    author = {Manfred Opper},
    title = {Statistical mechanics of learning: Generalization},
    journal = {The handbook of brain theory and neural networks},
    year = {1995},
    pages = {922-925}
}

@article{opper2001learning,
    author = {Manfred Opper},
    title = {Learning to generalize},
    journal = {Frontiers of Life},
    volume = {3},
    number = {part 2},
    year = {2001},
    pages = {763-775}
}

@article{belkin2020two,
  title={Two models of double descent for weak features},
  author={Mikhail Belkin and Daniel Hsu and Ji Xu},
  journal={SIAM Journal on Mathematics of Data Science},
  volume={2},
  number={4},
  pages={1167-1180},
  year={2020}
}

@article{hastie2022surprises,
  title={Surprises in high-dimensional ridgeless least squares interpolation},
  author={Trevor Hastie and Andrea Montanari and Saharon Rosset and Ryan J Tibshirani},
  journal={Annals of statistics},
  volume={50},
  number={2},
  pages={949},
  year={2022}
}

@misc{nakkiran2019more,
  title={More data can hurt for linear regression: Sample-wise double descent},
  author={Preetum Nakkiran},
  year={2019}
}

@misc{nakkiran2020optimal,
  title={Optimal regularization can mitigate double descent},
  author={Nakkiran, Preetum and Venkat, Prayaag and Kakade, Sham and Ma, Tengyu},
  year={2020}
}

@article{mei2022generalization,
  title={The generalization error of random features regression: Precise asymptotics and the double descent curve},
  author={Mei, Song and Montanari, Andrea},
  journal={Communications on Pure and Applied Mathematics},
  volume={75},
  number={4},
  pages={667-766},
  year={2022}
}

@article{belkin2019reconciling,
  title={Reconciling modern machine-learning practice and the classical bias--variance trade-off},
  author={Belkin, Mikhail and Hsu, Daniel and Ma, Siyuan and Mandal, Soumik},
  journal={Proceedings of the National Academy of Sciences},
  volume={116},
  number={32},
  pages={15849-15854},
  year={2019}
}

@book{james2021introduction,
  title={An introduction to statistical learning},
  author={James, Gareth and Witten, Daniela and Hastie, Trevor and Tibshirani, Robert and others},
  volume={112. Springer},
  number={1},
  publisher={Springer},
  year=2021
}

@article{woodworth2020kernel,
  title={Kernel and rich regimes in overparametrized models},
  author={Woodworth, Blake and Gunasekar, Suriya and Lee, Jason D and Moroshko, Edward and Savarese, Pedro and Golan, Itay and Soudry, Daniel and Srebro, Nathan},
  journal={arXiv preprint arXiv:2002.09277},
  year={2020}
}

@article{haochen2020shape,
  title={Shape Matters: Understanding the Implicit Bias of the Noise Covariance},
  author={HaoChen, Jeff Z and Wei, Colin and Lee, Jason D and Ma, Tengyu},
  journal={arXiv preprint arXiv:2006.08680},
  year={2020}
}

@article{kingma2013auto,
  title={Auto-Encoding Variational Bayes},
  author={Kingma, Diederik P and Welling, Max},
  journal={arXiv preprint arXiv:1312.6114},
  year={2013}
}

@article{blei2017variational,
  title={Variational inference: A review for statisticians},
  author={Blei, David M and Kucukelbir, Alp and McAuliffe, Jon D},
  journal={Journal of the American statistical Association},
  volume={112},
  number={518},
  pages={859-877},
  year={2017}
}

@inproceedings{devlin2019bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  booktitle={Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},
  pages={4171-4186},
  year={2019}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877-1901},
  year={2020}
}

@article{bommasani2021opportunities,
  title={On the opportunities and risks of foundation models},
  author={Bommasani, Rishi and Hudson, Drew A and Adeli, Ehsan and Altman, Russ and Arora, Simran and von Arx, Sydney and Bernstein, Michael S and Bohg, Jeannette and Bosselut, Antoine and Brunskill, Emma and others},
  journal={arXiv preprint arXiv:2108.07258},
  year={2021}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@inproceedings{chen2020simple,
  title={A simple framework for contrastive learning of visual representations},
  author={Chen, Ting and Kornblith, Simon and Norouzi, Mohammad and Hinton, Geoffrey},
  booktitle={International Conference on Machine Learning},
  pages={1597-1607, PMLR},
  year={2020},
  organization={PMLR}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{luo2018algorithmic,
  title={Algorithmic Framework for Model-based Deep Reinforcement Learning with Theoretical Guarantees},
  author={Luo, Yuping and Xu, Huazhe and Li, Yuanzhi and Tian, Yuandong and Darrell, Trevor and Ma, Tengyu},
  booktitle={International Conference on Learning Representations},
  year={2018},
}